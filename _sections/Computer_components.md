---
layout: default
title: "Computer components"
--- 

#### Processor

##### Basics of a CPU

Processors, or CPU's, are the "beating heart" of a computer, and as such, perform many more tasks than the ones that will be discussed in this text. The focus lies on the floating point calculation capabilities and the memory subsystems, as well as the interfaces.

The traditional CPU ([Central Processing Unit](https://en.wikipedia.org/wiki/Central_processing_unit)) is an Integrated Circuit (IC) that executes the logic, [arithmetic](https://en.wikipedia.org/wiki/Arithmetic), input/output (I/O) and control operations that are prescribed by software running on the computer. As time passed, many other subsystems of computers got integrated into the processor package (die), making the functions that the traditional CPU performs only a subset of all the functions that a modern processor performes. A "core" of a modern processor is a separate unit that performes all the tasks of a traditional CPU.

Modern processor cores are very diverse, complex and multi-faceted, varying wildly with ISA, microarchitecture, intended platform and manufacturer. A discussion about CPU's that would include all these variations would be impossible, necessitating a confinement. This discussion will try to be as generic as possible, but the focus lies on an Intel based server CPU of the "Skylake-SP" microarchitecture.

Intel dominates the PC/laptop as well as the HPC/Supercomputer CPU market, making the restriction towards an Intel x86-64 based CPU justified. Considering the fact that almost all Laptops and workstations contain CPU's that are (to a varying extend) derived from their server oriënted counterparts, focusing the discussion around a server CPU seems logical as well. The Skylake-SP microarchitecture was chosen because it is very recent (at the time of writing), contains some very significant advancements for scientific computing workloads and is used in a cluster available to the MEFD group at the TU/e.

##### System on a Chip

Modern processors are best decribed by the ["System on a Chip" (SoC)](https://en.wikipedia.org/wiki/System_on_a_chip) moniker, containing many of the core components of a computer. As such, most contain the following subsystems:

 - Cores
 - Memory controller
 - Cache
 - Interfaces
 - Graphics (included in most consumer oriënted CPU's)

##### Instruction set architecture

An Instruction Set Architecture ([ISA](https://en.wikipedia.org/wiki/Instruction_set_architecture)) is an abstract model of a computer and contains a collection of machine instruction definitions. Examples of common ISA's are x86-64, x86 and ARM, with x86-64 being the most common ISA for CPU's in servers, as well as consumer oriënted computers.

An ISA is one of the most important aspects of a CPU, because it formes the link between software and hardware. ISA's where introduced to make programming software easier, which could now be written in terms of ISA instructions in stead of low level [machine code](https://en.wikipedia.org/wiki/Machine_code). This made it possible to execute the same computer program on different computers, without any modification of the code.

An implementation of an ISA, called a [microarchitecture (uarch)](https://en.wikipedia.org/wiki/Microarchitecture), is the hardware based realisation of these machine instruction definitions (disregarding [microcode](https://en.wikipedia.org/wiki/Microcode)). Any specific uarch can also support extensions to its ISA, common examples are VT-d, AES-NI, SSE4 and AVX2. These extensions are additions to the abstract computer model of an ISA and contain specific instructions to accelerate certain tasks of a computer, like AES data encryption, virtualization and vector mathematics.

Some better known examples of microarchitectures are [Intel i386](https://en.wikipedia.org/wiki/Intel_80386), [Intel Nahelem](https://en.wikipedia.org/wiki/Nehalem_(microarchitecture)), [Intel Haswell](https://en.wikipedia.org/wiki/Haswell_%28microarchitecture%29), [AMD K8](https://en.wikipedia.org/wiki/AMD_K8), [AMD Bulldozer](https://en.wikipedia.org/wiki/Bulldozer_(microarchitecture)) and [AMD Zen](https://en.wikipedia.org/wiki/Zen_(microarchitecture)). 

##### Threads and cores

A [thread](https://en.wikipedia.org/wiki/Thread_(computing)) is a chain of instructions that is to be executed by the CPU. Each thread is generated by a process, which can loosely be described as an instance of a computer program. A single core of a CPU can execute one thread at a time, but using a technique called timeslicing and the concept of [context switching](https://en.wikipedia.org/wiki/Context_switch), can handle multiple threads concurrently.

Multithreading (software) allows a single process to spawn a multitude of threads, deviding the workload of that process. Performance benefits (can) arise when these threads are executed in parallel on multiple cores of a CPU.

The specifications of a CPU may contain references to the number of threads it "has", which should be interpreted as the maximum amount of threads it can "execute" at the same time. The fact that a single CPU core can only execute one thread at a time doesn't change, even if the CPU specifications state that it has more (twice) threads then cores. This has to do with a hardware based technique called simultaneous multithreading ([SMT](https://en.wikipedia.org/wiki/Simultaneous_multithreading)), which will be discussed later.

##### Cache

Quick access to data is critical for the performance of a CPU, making data flow and storage a mayor aspect of a CPU. The main memory of a computer (DRAM) has a relatively high latency and low bandwidth compared to the needs of modern CPU cores, which is where [cache](https://en.wikipedia.org/wiki/CPU_cache) comes into play. Cache is storage subsystem of the CPU, focussed on high bandwidth and low latency, sacrificing capacity, cost and complexity. It contains, among other things, copies of the data that the CPU (or process) "predicts" it will access often or in the near future, reducing the loading time of that data. A "cache-miss" refers to the situation where data is requested, but not stored in cache, resulting in a much longer loading time. Avoiding cache-misses is a large part of software (and hardware) optimization and can lead to very substantial performance improvements.

Cache memory is a lot faster, and generally superior on many fronts, compared to main memory, because cache is made from SRAM and main memory is made from DRAM. Each SRAM memory cell requires 6 transistors to store a bit, whereas DRAM requires only one transistor (and a small capacitor) per bit. The extra complexity of SRAM allows it to be much faster than DRAM, but the extra cost and space requirements on the [die](https://en.wikipedia.org/wiki/Die_(integrated_circuit)) of the CPU also make it much more expensive. The amount of cache placed on the CPU is thus relatively small, typically about 1:1.000, compared to the amount of main memory placed in a computer.

Cache memory pressure and the ever increasing speed of CPU cores lead to the development of multiple levels of cache. This layered structure has the advantage that it can address both the memory pressure problem as well as the demand for faster data access, without resulting in prohibitive costs. The upper most layer of cache, L1, has gotten significantly faster over time, but did not really increase much in capacity. The lowest level of cache, typically L3, saw the highest increase in capacity, but is also substantially slower then L1.

The development of multi-core processors and several levels of cache created an additional task for cache; inter-core communication. Each core has its own private part of L1 and L2 cache, whereas L3 cache is shared between the cores.

##### Intel Xeon Gold 1632

![CPU](../image/Skylake-SP-Gold-1632.png){:width="800px"}

This example CPU is the [Intel Xeon Gold 1632](https://ark.intel.com/products/123541/Intel-Xeon-Gold-6132-Processor-19_25M-Cache-2_60-GHz). 

It contains:
 - 14 cores and 28 threads
 - 6 channel DDR4 ECC memory controller
 - 19.25 MiB L3 cache
 - 14 MiB (1 MiB/c) L2 cache
 - 0.875 MiB (64 KiB/c) L1 cache
 - 48 PCI-e v3.0 lanes
 - 2 AVX-512 FMA units per core